# Future Skills Klassifikator

## Hintergrund

Franziska Weber hat einen [Future Skills-Classifier](http://srv-data01:30080/hex/future_skill_classification) trainiert, der per [API](http://srv-data01:30080/hex/future_skill_classifier_api) abrufbar ist. Leider k√∂nnen einzelne Dependencies nicht aufgel√∂st, verschiedene Klassen und Pakete nicht installiert werden, weshalb der Classifier nicht mehr zum laufen gebracht werden konnte. Die entsprechenden Codes des Klassifikators sind ebenfalls (f√ºr Python-Novizen üòë) nicht ohne Weiteres nachvollziehbar. Da die wertvolle Vorarbeit von Franziska Weber also nicht mehr recht zug√§nglich ist, wird aus Effizienzgr√ºnden ein eigener Klassifikator trainiert, der allerdings - grosso modo - ihrer Vorgehensweise (SetFit-Approach) und ihren Parametereinstellungen folgt. Der Klassifikator soll jedoch dieses Mal in der Programmierung und Funktionsweise auch f√ºr Au√üenstehende m√∂glichst leicht nachvollziehbar, und √ºber [huggingface.co](https://huggingface.co/) einfach abrufbar sein. Auf diese weise soll eine m√∂glichst barrierefreie Nutzung und ggf. anfallendes debugging üòä auch f√ºr Nicht-Informatiker\*innen einfach zu wenig zeitintensiv zu bewerkstelligen sein.

Dieser Ma√ügabe entsprechen werden die Codes des Klassifikators detailliert kommentiert und (f√ºr R-User, Soziolog\*innen und Psycholog\*innen) m√∂glichst intuitiv programmiert.

##  SetFit: Few-Shot Classification f√ºr Future Skills

Im Anschluss an die Vorarbeit von Franziska Weber bleibt es Ziel, mit dem auf [`BERT`](https://medium.com/@shaikhrayyan123/a-comprehensive-guide-to-understanding-bert-from-beginners-to-advanced-2379699e2b51) basierenden [`SetFit`](https://huggingface.co/blog/setfit) einen vortrainierten Sentence Transformer *feinzutunen*, der Future Skills aus **Kurstiteln**, **Beschreibungen** oder **Lernzielen** vorhersagen kann. Das vorgehen im Rahmen des few-shot-classifiers verl√§uft dabei wie folgt:

1. Ein vorab trainierter Sentence Transformer wie Sentence-BERT generiert kontextuelle Text-Embeddings. Die Trainingsdaten, die im Rahmend es few-shot learning ggf. aus sehr wenigen Beispielen pro Label bestehen k√∂nnen, werden in Text-Embeddings umgewandelt. Jedes Textbeispiel wird zu einem numerischen Vektor, der seine Bedeutung im Kontext repr√§sentiert.
2. SetFit f√ºhrt eine kontrastive Lernphase durch. In dieser Phase werden Paare von S√§tzen erzeugt:

   - Positive Paare: Zwei S√§tze mit demselben Label.
   - Negative Paare: Zwei S√§tze mit unterschiedlichen Labels.

    Ziel ist es, die hinsichtlich der Future Skills √§hnlichen Kurstitel/-beschreibungen im Raum der Embeddings n√§her zueinander zu bringen und un√§hnliche zu differenzieren. Dadurch wird das Modell auf die Klassifikation von Future Skills spezialisiert.
3. Nach dem kontrastiven Lernen werden die Embeddings verwendet, um einen einfachen Klassifikator zu trainieren, z.B. einen logistischen Regressions-Klassifikator. Dieser Klassifikator wird auf den erzeugten Embeddings trainiert, um multilabel Vorhersagen zu treffen.

Da Trainings- und Testdaten in jedem Fall in den Anwendungsfall des FS-Frameworks knapp sind, ist das Few-Shot-Learning eine vielversprechende Alternative zu klassischen Transformern. SetFit, ein Beispiel f√ºr Few-Shot-Learning, kann mit nur wenigen Beispielen pro Klasse √§hnliche Ergebnisse erzielen wie traditionelles Finetuning mit vielen Daten.

## Literatur

Eine kurze Einf√ºhrung in SetFit bieten Tunstall et al. 2022 [^2]. F√ºr weitere Details bzgl. Transformermodelle siehe Vaswani et al. 2017.[^3]. F√ºr eine √úberblick √ºber BERT siehe Reimers & Gurevych 2019[^4]. F√ºr die Nutzung bereits Trainierter Transformer siehe Chollet 2021 [^5]

## Daten

### Trainingsdaten

Von Yannic Hinrichs wurden per String-Match Trainingsdaten erzeugt, die um weitere Daten erg√§nzt wurden, die keine Future Skills enthalten. Die Daten wurden weiterhin durch Yannic Hinrichs h√§ndisch kontrolliert. Der entsprechende R-Code findet sich [hier](R/Create_Traindata_FS_Classifier_hya.R).

Alternativ bestehen weiterhin die Daten, die Franziska Weber f√ºr das Training ihres Classifiers verwendet hat. Dieses werden derzeit (Stand 21.10.24) ebenfalls f√ºr das Training des folgenden Classfiers verwendet.

Die Trainingsdaten befinden sich hier:

### Testdaten

Um die Qualit√§t der Classifier zu bestimmen, m√ºssen ggf. geeignete Testdaten erzeugt werden. Folgende Punkte sollten ber√ºcksichtigt werden:

1. Sampling und Labeling: Zun√§chst muss eine repr√§sentative Stichprobe der Kursbeschreibungen gezogen werden, die manuell gelabelt wird. F√ºr den Start k√∂nnten 500‚Äì1.000 Beispiele als eine ausreichend gro√üe Stichprobe dienen, insbesondere, wenn du viele Skills klassifizierst und sicherstellen m√∂chtest, dass jede Skill ausreichend abgedeckt wird. Pro Skill sollten 50-100 m√∂glichst variationsreiche Daten gelabelt vorliegen [^1].
2. Balance und Coverage: Sollten Skills in der GG ggf. seltener vorkommen, sollte diese dennoch in den Testdaten hinreichend h√§ufig vertreten sein, um verzerrungen bei der Klassifikation zu vermeiden. Rule of Thumb: 50-100 F√§lle pro Skill. 
3. Testgr√∂√üe in Relation zur Modellgr√∂√üe: Die Testdaten sollten 20% der Gesamtdaten ausmachen. 
4. Iteratives Labeling und Evaluierung: Es sollte iterativ vorgegangen werden: Begonnen wird mit einem kleineren, manuell gelabelten Testdatensatz, um den Klassifikator initial zu evaluieren. Sollte sich herausstellen, dass die Performance in bestimmten Bereichen stark schwankt oder die Varianz hoch ist, kann durch das Labeln weiterer Daten gezielt nachgesteuert werden. Auf diese Weise l√§sst sich das Modell schrittweise verbessern und validieren, um eine stabilere und genauere Klassifikation zu erreichen. 

## Environment mit Poetry

Die Verwendung von Environments sind in Python besonders beim Trainieren eines Classifiers sinnvoll, da sie dabei helfen, Abh√§ngigkeiten zwischen verwendeten Paketen sauber zu verwalten und Konflikte zu vermeiden. Ein Environment isoliert die Bibliotheken, die wir f√ºr den Classifier ben√∂tigen, und stellt zeitgleich sicher, dass andere Python-Projekte davon unber√ºhrt bleiben. Dies verhindert Versionskonflikte und macht es einfacher, Projekte auf anderen Rechnern oder von anderen Mitarbeiter\*innen reproduzierbar zu machen.

F√ºr die Erzeugung des Enviroments wurde [Poetry](https://python-poetry.org/) verwendet. Poetry bietet gegen√ºber klassischen Python-Enviroment-L√∂sungen nicht nur die Verwaltung von Abh√§ngigkeiten, sondern vereinfacht dar√ºber hinaus den gesamten Workflow im Kontext des Paketmanagements: Poetry automatisiert die Installation, Aktualisierung und das Sperren von Abh√§ngigkeiten mithilfe der Dateien pyproject.toml und poetry.lock, wodurch sichergestellt wird, dass alle Projektbeteiligten dieselben Versionen verwenden. Gleichzeitig erstellt es virtuelle Umgebungen, die verhindern, dass die Bibliotheken mit anderen Projekten auf deinem System in Konflikt geraten. Im Gegensatz zu einfachen Python-Environments bietet Poetry ein robustes Tool, das sowohl f√ºr den Dependency-Management-Prozess als auch f√ºr das Ver√∂ffentlichen von Python-Paketen optimiert ist.

Das Poetry-Enviorment wird [hier](Gen_Poetry_Enviorment.ipynb) erstellt. Die dadruch erzeugten `poetry.lock` und `pyproject.toml` befinden sich ebenfalls im Stammverzeichnis des Repositorys.

# Aufbau des Repos

Das Repo ist folgenderma√üen aufgebaut:

```bash
C:.
‚îÇ   .gitignore
‚îÇ   Gen_Poetry_Enviorment.ipynb
‚îÇ   poetry.lock
‚îÇ   pyproject.toml
‚îÇ   README.md
‚îÇ
‚îú‚îÄ‚îÄ‚îÄPy
‚îÇ   ‚îÇ   poetry_prompts.py
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄnotebooks
‚îÇ           Tiny_Few_Shot_Multi_Lable_Classifer.ipynb
‚îÇ           Use_Tiny_Few_Shot_Multi_Lable_Classifier.ipynb
‚îÇ
‚îî‚îÄ‚îÄ‚îÄR
        Create_Traindata_FS_Classifier_hya.R
        plot_hex_skills.R
```

Im Idealfall muss f√ºr die Verwendung des Classifiers lediglich das Notebook `Py\notebooks\Use_Tiny_Few_Shot_Multi_Lable_Classifier.ipynb` verwendet werden. Ein Guide ist in das entsprechende Notbook eingearbeit. Es kann daher intuitiv und selbsterkl√§rend verwendet werden. Als Datengrundlagen sollen die jeweils aktuellen HEX-Daten gelten. Ihr aktueller Speicherort kann immer bei Eike Schr√∂der angefragt werden.

# Results

Das trainierte Model wurde sowohl lokal, als auch auf dem Hugging-Face-Hub abgelegt. 

Die lokale Version findet sich [hier](). Die Kopie auf Hugging Face kann [hier](https://huggingface.co/Chernoffface/fs-setfit-model) abgerufen werden. 

F√ºr eine einfache Anwendung kann das Modell wie folgt f√ºr die prediction von Future Skills verwendet werden:

```python
from setfit import SetFitModel

# Download from the ü§ó Hub
model = SetFitModel.from_pretrained("Chernoffface/fs-setfit-multilable-model")
# Run inference
preds = model("Grundlagen der Programmierung mit C++")
```
 

[^1]: Figueroa, R.L., Zeng-Treitler, Q., Kandula, S. et al. (2012). Predicting sample size required for classification performance. BMC Med Inform Decis Mak 12, 8 (2012). https://doi.org/10.1186/1472-6947-12-8
[^2]: Tunstall, L., Reimers, N., Jo, U. E. S., Bates, L., Korat, D., Wasserblat, M., & Pereg, O. (2022). Efficient few-shot learning without prompts. arXiv preprint arXiv:2209.11055.
[^3]: Vaswani, A. (2017). Attention is all you need. Advances in Neural Information Processing Systems.
[^4]: Devlin, J. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.
[^5]: Pfeiffer, J., Kamath, A., R√ºckl√©, A., Cho, K., & Gurevych, I. (2020). Adapterfusion: Non-destructive task composition for transfer learning. arXiv preprint arXiv:2005.00247.
