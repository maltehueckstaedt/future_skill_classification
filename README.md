# Future Skills Klassifikator

## Hintergrund

Der Future Skill Classifier soll â€” nach letztem Stand â€” sechs technologische Kompetenzen anhand von Kurstiteln, Kursbeschreibungen und Lernzielen klassifizieren.

ğŸš€ Franziska Weber hat einen [Future Skills-Classifier](http://srv-data01:30080/hex/future_skill_classification) trainiert, der per [API](http://srv-data01:30080/hex/future_skill_classifier_api) abrufbar ist. Leider kÃ¶nnen einzelne Dependencies nicht aufgelÃ¶st werden, verschiedene Klassen und Pakete nicht installiert werden, weshalb der Classifier nicht mehr zum Laufen gebracht werden konnte. Die entsprechenden Codes des Klassifikators sind ebenfalls (fÃ¼r Python-Novizen ğŸ˜‘) nicht ohne Weiteres nachvollziehbar.Da die wertvolle Vorarbeit von Franziska Weber also nicht mehr recht zugÃ¤nglich ist, wird aus EffizienzgrÃ¼nden ein eigener Klassifikator trainiert, der allerdings â€“ grosso modo â€“ ihrer Vorgehensweise (SetFit-Approach) und ihren Parametereinstellungen folgt. Der Klassifikator soll jedoch dieses Mal in der Programmierung und Funktionsweise auch fÃ¼r Nicht-Informatiker\*innen mÃ¶glichst leicht nachvollziehbar und Ã¼ber [huggingface.co](https://huggingface.co/) einfach abrufbar sein. Auf diese Weise soll eine mÃ¶glichst barrierefreie Nutzung und ggf. anfallendes Debugging ğŸ¤¯ auch fÃ¼r Nicht-Informatiker\*innen einfach und wenig zeitintensiv zu bewerkstelligen sein.

Dieser MaÃŸgabe entsprechend werden die Codes des Klassifikators detailliert kommentiert und mÃ¶glichst intuitiv programmiert.


##  SetFit: Few-Shot Classification fÃ¼r Future Skills

Im Anschluss an die Vorarbeit von Franziska Weber ğŸ› ï¸ bleibt es Ziel, mit dem auf [`BERT`](https://medium.com/@shaikhrayyan123/a-comprehensive-guide-to-understanding-bert-from-beginners-to-advanced-2379699e2b51) basierenden [`SetFit`](https://huggingface.co/blog/setfit) ğŸ¤– einen vortrainierten Sentence Transformer ğŸŒ *feinzutunen*, der Future Skills ğŸ“š aus **Kurstiteln**, **Beschreibungen** oder **Lernzielen** vorhersagen kann. FÃ¼r eine Ãœbersicht des Vorgehens von Setfit eignen sich *Tunstall et al. 2022* ğŸ“– im speziellen und *Alammar & Grootendorst 2024* ğŸ“š im allgemeinen.

Da Trainings- und Testdaten ğŸ§ª im Fall des FS-Frameworks knapp sind, ist das Few-Shot-Learning ğŸŒŸ eine vielversprechende Alternative zu klassischen Transformern. Das durch SetFit spezifizierte Few-Shot-Modell `paraphrase-multilingual-MiniLM-L12-v2`, ist in diesem Zusammenhang in der Lage, mit nur wenigen Beispielen pro Klasse Ã¤hnlich gute Ergebnisse zu erzielen wie herkÃ¶mmliche Modelle, die auf umfangreichen, vollstÃ¤ndig annotierten DatensÃ¤tzen trainiert wurden.

## Daten

### Trainingsdaten

Yannic Hinrichs erzeugte Trainingsdaten, indem er per String-Match in den Kurstiteln und Kursbeschreibungen nach Schlagworten suchte, die auf Future Skills hinweisen. Die so vergebenen Labels wurden hÃ¤ndisch korrigiert und in den Trainingsdatensatz aufgenommen. AuÃŸerdem wurden FÃ¤lle ergÃ¤nzt, in denen das String-Matching keine Future Skills detektierte: Ein Teil dieser FÃ¤lle enthielt keine Kursbeschreibung, der andere enthielt eine Kursbeschreibung. Diese "negativen" FÃ¤lle wurden jedoch nicht hÃ¤ndisch kontrolliert. Der entsprechende R-Code findet sich [hier](R/Create_Traindata_FS_Classifier_hya.R).

Alternativ liegen weiterhin die Trainingsdaten vor, die Franziska Weber fÃ¼r das Training ihres Classifiers verwendet hat. Diese werden derzeit aufgrund der besseren Klassifizierungsergebnisse des resultierenden Classifiers verwendet. Die Trainingsdaten von Franziska Weber wurden folgendermaÃŸen erzeugt: FÃ¼r die Few-Shot-Klassifikation wurden synthetische BeispielsÃ¤tze erstellt, in denen ein einheitliches Satzmuster (â€Die Veranstaltung behandelt das Thema Xâ€œ) verwendet wird. Die Beschreibung â€Xâ€œ basiert auf dem Namen und Synonymen des Skills und wurde (teilweise) vom Felix SÃ¼ÃŸenbach Ã¼berprÃ¼ft. Diese Methode ermÃ¶glicht genÃ¼gend Trainingsdaten pro Klasse zu erzeugen, obwohl sie eventuell von der realen Sprache in den HEX-Daten abweichen kÃ¶nnte. FÃ¼r einen detaillierten Ãœberblick Ã¼ber das Vorgehen siehe das folgende [README.md](http://srv-data01:30080/hex/future_skill_classification#example-data).

Die Trainingsdaten befinden sich [hier](https://stifterverband.sharepoint.com/sites/Dateiablage/SVDaten/Forms/AllItems.aspx?ct=1730716805420&or=Teams%2DHL&ga=1&LOF=1&id=%2Fsites%2FDateiablage%2FSVDaten%2FAbteilungen%2FPuF%2FHEX%2FAnalyse%2FDaten%2FMaltes%5FFS%5FClassifier%2Fdata&viewid=3315becc%2De761%2D4c82%2D9e01%2D08b652d83ffd) auf dem Sharepoint.


## Environment mit Anaconda

Die Verwendung von Environments sind in Python besonders beim Trainieren eines Classifiers sinnvoll, da sie dabei helfen, AbhÃ¤ngigkeiten zwischen verwendeten Paketen sauber zu verwalten und Konflikte zu vermeiden. Ein Environment isoliert die Bibliotheken, die wir fÃ¼r den Classifier benÃ¶tigen, und stellt zeitgleich sicher, dass andere Python-Projekte davon unberÃ¼hrt bleiben. Dies verhindert Versionskonflikte und macht es einfacher, Projekte auf anderen Rechnern oder von anderen Mitarbeiter\*innen reproduzierbar zu machen.

Das Conda-Environment fÃ¼r die Erzeugung des Classifiers wird [hier](Gen_Conda_Environment.ipynb) erstellt. Die entsprechende `environment.yaml` befindet sich ebenfalls im Stammverzeichnis des Repositorys.

### Installation des Environments
 
1. Laden und Installieren von Miniconda: https://docs.anaconda.com/miniconda/
2. Das Arbeitsverzeichnis des Repositorys mit dem **Anaconda Prompt** Ã¶ffenen.
3. Mit `conda env create -f environment.yaml` das Environment erzeugen.
4. Sollte es (z.B. aufgrund des Proxys) zu Fehlermeldungen bei der Installation kommen, kÃ¶nnen einzelne Pakete auch seperat nach installiert werden: Es muss sichergestellt werden, dass das Enviorment - so es installiert wurde - verwendet wird: Wir geben dafÃ¼r ebenfalls im  **Anaconda Prompt** `conda info --envs` ein. Das Environment, das aktiv ist, ist mit einem Asterisk gekennzeichnet (`*`). Sollte nicht unser Environment aktiv sein, aktivieren wir es mit: `conda activate fs_skills_classifier_env`. AnschlieÃŸend installieren wir die gewÃ¼nschten Pakete mit `conda install <Paketname>` oder `pip install <Paketname>` nach
5. AnschlieÃŸend sollte das Environment in VS Code bei der Verwendung eines Jupyter-Notebooks (z.B. `Py\notebooks\Use_Tiny_Few_Shot_Multi_Lable_Classifier.ipynb`) auswÃ¤hlbar sein.

# Aufbau des Repos

Das Repo ist folgendermaÃŸen aufgebaut:

```bash
C:.
â”‚   .gitignore
â”‚   environment.yaml
â”‚   Gen_Conda_Environment.ipynb
â”‚   README.md
â”‚
â”œâ”€â”€â”€data
â”‚       hex_classified_fs_without_lernziele.csv
â”‚       hex_classified_fs_with_lernziele.csv
â”‚       train_data_franziska.xlsx
â”‚
â”œâ”€â”€â”€Py
â”‚   â”‚
â”‚   â””â”€â”€â”€notebooks
â”‚           gen_plot_datenportal_fs_skills.ipynb
â”‚           Tiny_Few_Shot_Multi_Lable_Classifer.ipynb
â”‚           Use_Tiny_Few_Shot_Multi_Lable_Classifier.ipynb
â”‚
â””â”€â”€â”€R
        Create_Traindata_FS_Classifier_hya.R
        plot_hex_skills.R
```

Im Idealfall muss fÃ¼r die Verwendung des Classifiers lediglich das Notebook `Py\notebooks\Use_Tiny_Few_Shot_Multi_Lable_Classifier.ipynb` verwendet werden. Ein Guide ist in das entsprechende Notebook eingearbeitet. Es kann daher intuitiv und selbsterklÃ¤rend verwendet werden. Als Datengrundlagen sollen die jeweils aktuellen HEX-Daten gelten.

# Results

Das trainierte Model wurde sowohl lokal, als auch auf dem Hugging-Face-Hub abgelegt. 

Die lokale Version findet sich [hier](). Die Kopie auf Hugging Face kann [hier](https://huggingface.co/Chernoffface/fs-setfit-multilable-model) abgerufen werden. 

FÃ¼r eine einfache Anwendung kann das Modell wie folgt fÃ¼r die prediction von Future Skills verwendet werden:

```python
from setfit import SetFitModel

# Download from the ğŸ¤— Hub
model = SetFitModel.from_pretrained("Chernoffface/fs-setfit-multilable-model")
# Run inference
preds = model("Grundlagen der Programmierung mit C++")
```

## Ein- und weiterfÃ¼hrende Literatur

Ein wunderbar intuitive EinfÃ¼hrung in Large Language Models bieten *Alammar & Grootendorst 2024*[^6]. Eine kurze EinfÃ¼hrung in `SetFit` bieten *Tunstall et al. 2022* [^2]. FÃ¼r weiterreichende Details bzgl. Transformermodelle siehe *Vaswani et al. 2017*.[^3]. FÃ¼r eine Ãœberblick Ã¼ber BERT siehe *Reimers & Gurevych 2019*[^4]. FÃ¼r die Nutzung bereits trainierter Transformer siehe *Chollet 2021* [^5]

## Quellen

[^1]: Figueroa, R.L., Zeng-Treitler, Q., Kandula, S. et al. (2012). Predicting sample size required for classification performance. BMC Med Inform Decis Mak 12, 8 (2012). https://doi.org/10.1186/1472-6947-12-8
[^2]: Tunstall, L., Reimers, N., Jo, U. E. S., Bates, L., Korat, D., Wasserblat, M., & Pereg, O. (2022). Efficient few-shot learning without prompts. arXiv preprint arXiv:2209.11055.
[^3]: Vaswani, A. (2017). Attention is all you need. Advances in Neural Information Processing Systems.
[^4]: Devlin, J. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.
[^5]: Pfeiffer, J., Kamath, A., RÃ¼cklÃ©, A., Cho, K., & Gurevych, I. (2020). Adapterfusion: Non-destructive task composition for transfer learning. arXiv preprint arXiv:2005.00247.
[^6]: Alammar, J., & Grootendorst, M. (2024). Hands-On Large Language Models. " O'Reilly Media, Inc.".
