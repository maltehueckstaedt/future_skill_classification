{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiny few shot classifer\n",
    "\n",
    "Im folgenden wird ein few shot classifier für multilabels im [SetFit-Frame](https://huggingface.co/blog/setfit) Format erzeugt. Gearbeitet wird mit `Python 3.12.3`.\n",
    "\n",
    "# Pakete laden\n",
    "\n",
    "In einem ersten Schritt werden die nötigen Pakete geladen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset  # Zum Laden von Datensätzen aus der Hugging Face `datasets` Bibliothek\n",
    "from sentence_transformers.losses import CosineSimilarityLoss  # Verlustfunktion basierend auf der Kosinusähnlichkeit, für Aufgaben wie Textähnlichkeit\n",
    "\n",
    "from setfit import SetFitModel, SetFitTrainer  # Zum Laden des SetFit-Modells und Trainers, speziell für Few-Shot Learning mit Satztransformern\n",
    "import pandas as pd  # Pandas für Datenmanipulation und -analyse\n",
    "from sklearn.preprocessing import LabelEncoder  # Zum Encoden von Labels in numerische Werte für maschinelles Lernen\n",
    "import os  # Für den Umgang mit Betriebssystemfunktionen (z.B. Dateipfade)\n",
    "from datasets import Dataset, DatasetDict  # Zum Erstellen und Verwalten von Datensätzen in Hugging Face `datasets`-Format\n",
    "from sklearn.model_selection import train_test_split  # Zum Aufteilen der Daten in Trainings- und Testsets\n",
    "\n",
    "from transformers import TrainingArguments  # Zum Festlegen von Trainingsparametern für Modelle in der Transformers-Bibliothek\n",
    "\n",
    "import torch  # Ermöglicht die GPU-Nutzung und effiziente Verarbeitung von Tensoren\n",
    "import numpy as np  # Für numerische Berechnungen und Arbeiten mit Arrays\n",
    "\n",
    "import re\n",
    "import html\n",
    "\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arbeitsverzeichnis\n",
    "\n",
    "Es wird weiterhin das Rootverzeichnis bestimmt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hueck\\OneDrive\\Dokumente\\GitHub\\future_skill_classification\n"
     ]
    }
   ],
   "source": [
    "# checke home-verzeichnis\n",
    "print(os.getcwd())\n",
    "# setze home-verzeichnis\n",
    "os.chdir('c:/Users/Hueck/OneDrive/Dokumente/GitHub/future_skill_classification/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten\n",
    "\n",
    "## Daten laden\n",
    "\n",
    "Das zur Zeit keine Daten für das trainieren eines multilable Classifiers vorliegen, werden die Trainings-Daten genutzt, die ursprünglich von Franziska Weber und Felix Süßenbach erzeugt wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['sentence', 'Data Analytics & KI', 'Softwareentwicklung', 'Nutzerzentriertes Design', 'IT-Architektur', 'Hardware/Robotikentwicklung', 'Quantencomputing', 'Digital Literacy', 'Digital Ethics', 'Digitale Kollaboration', 'Digital Learning', 'Agiles Arbeiten', 'Lösungsfähigkeit', 'Kreativität', 'Unternehmerisches Handeln & Eigeninitiative', 'Interkulturelle Kommunikation', 'Resilienz', 'Urteilsfähigkeit', 'Innovationskompetenz', 'Missionsorientierung', 'Veränderungskompetenz', 'Dialog- und Konfliktfähigkeit'],\n",
      "    num_rows: 1577\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Laden der Excel-Datei\n",
    "df = pd.read_excel('data/train_data_franziska.xlsx')\n",
    " \n",
    "# 1. Ersetze NaN-Werte durch 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "# 2. Ersetze unendliche Werte durch 0\n",
    "df.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "df[df.select_dtypes(include='number').columns] = df.select_dtypes(include='number').astype('int64')\n",
    "\n",
    " \n",
    "df_cleaned = df[~(df.select_dtypes(include='number').eq(0).all(axis=1))]\n",
    "\n",
    "\n",
    "\n",
    "# Für die weitere Verarbeitung werden die Daten ins  Hugging Face Dataset-Format transformiert. \n",
    "\n",
    "# /////////////////////////////////////////////////\n",
    "# Hinweis: Das Dataset-Format der Hugging Face datasets-Bibliothek basiert auf Apache Arrow und ist speichereffizient, was schnelles Laden und Verarbeiten großer Datensätze ermöglicht. Es integriert sich nahtlos in Machine-Learning-Workflows und unterstützt einfache Transformationen und Vorverarbeitung durch Methoden wie .map(). Zudem ist es flexibel und kompatibel mit Pandas DataFrames sowie gängigen Frameworks wie PyTorch und TensorFlow.\n",
    "#//////////////////////////////////////////////////\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "print(dataset)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten verarbeiten\n",
    "\n",
    "### Feature Auswahl\n",
    "\n",
    "In einem ersten Schritt werden die Features des Classifiers ausgewählt. Da sich insbesondere *klassische* und *transformative Future Skills* als schwer nachvollziehbar in den Daten erwiesen haben, werden diese aus dem Classifier ausgeschlossen, ebenso wie die Kurstitel und -beschreibungen (`sentence`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Analytics & KI', 'Softwareentwicklung', 'Nutzerzentriertes Design', 'IT-Architektur', 'Hardware/Robotikentwicklung', 'Quantencomputing', 'Digital Literacy', 'Digital Ethics', 'Digitale Kollaboration', 'Digital Learning', 'Agiles Arbeiten']\n"
     ]
    }
   ],
   "source": [
    "# ziehe column names als Liste\n",
    "features = dataset.column_names\n",
    "\n",
    "# definiere skills, die nicht vom classifier berücksichtigt werden\n",
    "to_remove = ['sentence','Lösungsfähigkeit', 'Kreativität', 'Unternehmerisches Handeln & Eigeninitiative', \n",
    "             'Interkulturelle Kommunikation', 'Resilienz', 'Urteilsfähigkeit', \n",
    "             'Innovationskompetenz', 'Missionsorientierung', 'Veränderungskompetenz', \n",
    "             'Dialog- und Konfliktfähigkeit']\n",
    "\n",
    "# schließe die oben definierten Variablen aus der Feature-Liste aus\n",
    "filtered_features = [feature for feature in features if feature not in to_remove]\n",
    "\n",
    "features = filtered_features\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot-Encoding\n",
    "\n",
    "Für das Trainieren des Classifiers wird im folgenden ein *One-Hot-Encoding*-Array der Features erzeugt. Dies ist deshalb nötig, da im folgenden ein Modell für ein Multi-Label-Szenario trainiert werden soll: Ein Kursangebot kann den erwerb mehrerer Future Skills versprechen, etwa Softwareentwicklung **&** IT-Architektur. Das One-Hot-Encoding wird benötigt, um die Labels der Features in eine Form zu bringen, die das Classifier Modell von SetFit korrekt verarbeiten kann. Es stellt sicher, dass alle Klassen gleichwertig behandelt werden, und ermöglicht die Berechnung von Ähnlichkeiten verschiedener Kursinhalte.\n",
    "\n",
    "Um den *One-Hot-Encoding*-Array zu erzeugen definieren wir `encode_labels(record)`: Diese Funktion geht durch jede Zeile eines Data Frames und erstellt eine neue Spalte namens `labels`. In dieser Spalte werden die Werte aus den oben definierten \"features\" gesammelt und in eine Liste gepackt. Diese Liste enthält Werte der Features.\n",
    "\n",
    "Beispiel: Mit Blick auf die Features 'Data Analytics & KI', 'Softwareentwicklung' und 'Nutzerzentriertes Design', könnte ein Zeilenvektor des Arrays eines Kurses der sich mit Data Analytics & KI / Softwareentwicklung beschäftigt so aussehen: `[1, 1, 0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hueck\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\utils\\_dill.py:379: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "  obj.co_lnotab,  # for < python 3.10 [not counted in args]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22afa55a715e4af4a0f8229547aebb46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1577 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generiere Funktion für One-Hot-Encoding für jede Zeile (record)\n",
    "def encode_labels(record):\n",
    "    return {\"labels\": [record[feature] for feature in features]}\n",
    "\n",
    "# wende Funktion auf train_data an\n",
    "dataset = dataset.map(encode_labels)\n",
    "\n",
    "# um die Daten übersichtlich im viewer zu betrachten: umwandlung und pandas data frame\n",
    "pd_dataset = dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erstellung von Test- und Trainingsdaten\n",
    "\n",
    "Im folgenden wird in `dataset` für jedes Feature (`f`) in der Liste `features` nach den Zeilen gesucht, in denen das Feature einen gültigen (nicht-leeren oder nicht-null) Wert hat. Aus diesen Zeilen (Indizes) werden dann zufällig 8 Beispiele ausgewählt. `np.where(dataset[f])` gibt die Indizes der Zeilen zurück, bei denen der Wert in der Spalte `f` `true` ist (also weder leer noch null). Wenn der Wert `false` ist (z.B. `0`, `NaN`, `None`, `False`, ein leerer String ''), wird diese Zeile ausgeschlossen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 801  838  862 1398  838 1245 1429 1424 1450  625 1136 1107  829 1109\n",
      " 1154  739 1518  964 1426 1576 1572 1574 1576 1481  809  529  325   96\n",
      " 1178  755  690  974  992 1471  320  804  112 1483  992  382 1470 1470\n",
      "   93 1466 1376 1470  571 1466  835 1495 1356 1452 1504 1495 1495  825\n",
      "  248 1485 1485 1402 1508  248 1432 1512 1189  928 1189 1189  836 1189\n",
      "  836  812  398  810  825  398 1003  952  825  810 1553 1549 1548 1546\n",
      " 1541 1550 1548 1555]\n"
     ]
    }
   ],
   "source": [
    "num_samples = 8\n",
    "samples = np.concatenate(\n",
    "    [np.random.choice(np.where(dataset[f])[0], num_samples) for f in features]\n",
    ")\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden wird einerseits der Trainingsdatensatz `train_dataset` anhand der oben definierten Indizes aus dem `samples`-Objekt erzeugt. Andererseits wird ein komplementärer Datensatz `eval_dataset` erzeugt, mit allen Indizes die nicht im `samples`-Objekt vorkommen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.select(samples)\n",
    "eval_dataset = dataset.select(\n",
    "    np.setdiff1d(np.arange(len(dataset)), samples)\n",
    ")\n",
    "\n",
    " \n",
    "# check data with pandas\n",
    "pd_train_dataset = train_dataset.to_pandas()\n",
    "pd_eval_dataset = eval_dataset.to_pandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelltraining\n",
    "\n",
    "Es wird das vortrainierte sentence-transformers-Modell `paraphrase-mpnet-base-v2` aus der Hugging Face Bibliothek geladen. Durch die Angabe der Strategie `one-vs-rest` wird das Modell für eine Multi-Label-Klassifikation konfiguriert, bei der jede Klasse eines Kurses einzeln vorhergesagt wird. Auf diese Weise wird es möglich, mehrere Skills pro Kurs zu identifizieren. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"sentence-transformers/paraphrase-mpnet-base-v2\"\n",
    " \n",
    "model = SetFitModel.from_pretrained(model_id, multi_target_strategy=\"one-vs-rest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der `SetFitTrainer` wird instanziiert, um das Modell auf den Trainings- und Evaluierungsdatensätzen zu trainieren. Eine Bewertung des Modells wird erst zu einem späteren Zeitpunkt möglich, wenn Testdaten vorliegen.\n",
    "\n",
    "1. Das vortrainierte `model` (siehe oben) wird als Grundlage für das Training verwendet, das auf dem Few-Shot Learning-Ansatz basiert. `paraphrase-mpnet-base-v2` ist ein vortrainiertes Modell aus der Sentence Transformers-Familie, das speziell für die Aufgabe der semantischen Textähnlichkeit und Paraphrasenerkennung entwickelt wurde. \n",
    "2. Der `train_dataset` enthält die Trainingsdaten, und der `eval_dataset` wird zu einem späteren Zeitpunkt genutzt, um die Klassifikations-Leistung des Modells während des Trainings zu bewerten.\n",
    "3. Die Verlustfunktion (`loss_class`) wird als *Cosine Similarity Loss* festgelegt. Die *Cosine Similarity Loss* ist eine Verlustfunktion, die darauf basiert, wie ähnlich sich zwei Vektoren sind. In diesem Fall werden die Ausgabevektoren des Modells und die Zielvektoren (also die \"Labels\") mithilfe der Kosinus-Ähnlichkeit verglichen. Je höher die Ähnlichkeit also, desto besser das Modell. \n",
    "4. Die `column_mapping` gibt an, welche Spalten in den Datensätzen die Texte (`sentence` → `text`) und die zugehörigen Labels (`labels` → `label`) enthalten, sodass das Modell die Daten korrekt interpretieren kann.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hueck\\AppData\\Local\\Temp\\ipykernel_30092\\2973711996.py:1: DeprecationWarning: `SetFitTrainer` has been deprecated and will be removed in v2.0.0 of SetFit. Please use `Trainer` instead.\n",
      "  trainer = SetFitTrainer(\n",
      "Applying column mapping to the training dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f9b70696664f74b10d7dd6670b8d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1577 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset, \n",
    "    #eval_dataset=eval_dataset,\n",
    "    loss_class=CosineSimilarityLoss,\n",
    "    num_iterations=20,\n",
    "    column_mapping={\"sentence\": \"text\", \"labels\": \"label\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun kann das Training beginnen: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num unique pairs = 63080\n",
      "  Batch size = 16\n",
      "  Num epochs = 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd2e95984e44977b92dd8ddc8dd0ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.2958, 'grad_norm': 2.32528018951416, 'learning_rate': 5.063291139240507e-08, 'epoch': 0.0}\n",
      "{'embedding_loss': 0.2471, 'grad_norm': 1.836930751800537, 'learning_rate': 2.5316455696202535e-06, 'epoch': 0.01}\n",
      "{'embedding_loss': 0.1602, 'grad_norm': 1.1381397247314453, 'learning_rate': 5.063291139240507e-06, 'epoch': 0.03}\n",
      "{'embedding_loss': 0.0884, 'grad_norm': 1.2985222339630127, 'learning_rate': 7.5949367088607605e-06, 'epoch': 0.04}\n",
      "{'embedding_loss': 0.056, 'grad_norm': 1.9718166589736938, 'learning_rate': 1.0126582278481014e-05, 'epoch': 0.05}\n",
      "{'embedding_loss': 0.0465, 'grad_norm': 1.1419466733932495, 'learning_rate': 1.2658227848101268e-05, 'epoch': 0.06}\n",
      "{'embedding_loss': 0.0431, 'grad_norm': 0.7483248114585876, 'learning_rate': 1.5189873417721521e-05, 'epoch': 0.08}\n",
      "{'embedding_loss': 0.0285, 'grad_norm': 0.5731155872344971, 'learning_rate': 1.7721518987341772e-05, 'epoch': 0.09}\n",
      "{'embedding_loss': 0.0224, 'grad_norm': 0.3748095631599426, 'learning_rate': 1.9971815107102595e-05, 'epoch': 0.1}\n",
      "{'embedding_loss': 0.0281, 'grad_norm': 0.3747982978820801, 'learning_rate': 1.9689966178128525e-05, 'epoch': 0.11}\n",
      "{'embedding_loss': 0.024, 'grad_norm': 0.47021782398223877, 'learning_rate': 1.9408117249154455e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2634e8d0615f4db39540f83b5cdbbaf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/5 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0271, 'grad_norm': 0.2962232828140259, 'learning_rate': 1.9126268320180385e-05, 'epoch': 0.14}\n",
      "{'embedding_loss': 0.0223, 'grad_norm': 0.4222840666770935, 'learning_rate': 1.8844419391206314e-05, 'epoch': 0.15}\n",
      "{'embedding_loss': 0.0314, 'grad_norm': 0.4079793691635132, 'learning_rate': 1.8562570462232244e-05, 'epoch': 0.16}\n",
      "{'embedding_loss': 0.0213, 'grad_norm': 0.45299822092056274, 'learning_rate': 1.8280721533258174e-05, 'epoch': 0.18}\n",
      "{'embedding_loss': 0.0176, 'grad_norm': 1.076499104499817, 'learning_rate': 1.7998872604284104e-05, 'epoch': 0.19}\n",
      "{'embedding_loss': 0.0235, 'grad_norm': 0.24857784807682037, 'learning_rate': 1.7717023675310034e-05, 'epoch': 0.2}\n",
      "{'embedding_loss': 0.0227, 'grad_norm': 0.24881407618522644, 'learning_rate': 1.7435174746335967e-05, 'epoch': 0.22}\n",
      "{'embedding_loss': 0.0143, 'grad_norm': 0.28781282901763916, 'learning_rate': 1.7153325817361894e-05, 'epoch': 0.23}\n",
      "{'embedding_loss': 0.0268, 'grad_norm': 0.4491312801837921, 'learning_rate': 1.6871476888387827e-05, 'epoch': 0.24}\n",
      "{'embedding_loss': 0.0235, 'grad_norm': 0.2551679313182831, 'learning_rate': 1.6589627959413757e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211a92fc069641fea32669953c4ac54e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/5 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0175, 'grad_norm': 0.6588782072067261, 'learning_rate': 1.6307779030439687e-05, 'epoch': 0.27}\n",
      "{'embedding_loss': 0.0227, 'grad_norm': 4.442176818847656, 'learning_rate': 1.6025930101465617e-05, 'epoch': 0.28}\n",
      "{'embedding_loss': 0.0172, 'grad_norm': 2.0481514930725098, 'learning_rate': 1.5744081172491546e-05, 'epoch': 0.29}\n",
      "{'embedding_loss': 0.0144, 'grad_norm': 0.6395565271377563, 'learning_rate': 1.5462232243517476e-05, 'epoch': 0.3}\n",
      "{'embedding_loss': 0.0138, 'grad_norm': 0.21709315478801727, 'learning_rate': 1.5180383314543406e-05, 'epoch': 0.32}\n",
      "{'embedding_loss': 0.0139, 'grad_norm': 2.9585299491882324, 'learning_rate': 1.4898534385569336e-05, 'epoch': 0.33}\n",
      "{'embedding_loss': 0.0162, 'grad_norm': 0.30282554030418396, 'learning_rate': 1.4616685456595266e-05, 'epoch': 0.34}\n",
      "{'embedding_loss': 0.019, 'grad_norm': 0.08543681353330612, 'learning_rate': 1.4334836527621196e-05, 'epoch': 0.36}\n",
      "{'embedding_loss': 0.0167, 'grad_norm': 0.2845315933227539, 'learning_rate': 1.4052987598647126e-05, 'epoch': 0.37}\n",
      "{'embedding_loss': 0.02, 'grad_norm': 1.4130609035491943, 'learning_rate': 1.3771138669673057e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e9925e012e4109abefd1d1f1d45c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/5 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0133, 'grad_norm': 0.45081907510757446, 'learning_rate': 1.3489289740698987e-05, 'epoch': 0.39}\n",
      "{'embedding_loss': 0.0156, 'grad_norm': 0.6863718032836914, 'learning_rate': 1.3207440811724917e-05, 'epoch': 0.41}\n",
      "{'embedding_loss': 0.0188, 'grad_norm': 0.9276122450828552, 'learning_rate': 1.2925591882750847e-05, 'epoch': 0.42}\n",
      "{'embedding_loss': 0.0103, 'grad_norm': 0.24063430726528168, 'learning_rate': 1.2643742953776777e-05, 'epoch': 0.43}\n",
      "{'embedding_loss': 0.0139, 'grad_norm': 0.229756698012352, 'learning_rate': 1.2361894024802708e-05, 'epoch': 0.44}\n",
      "{'embedding_loss': 0.0125, 'grad_norm': 0.9742169380187988, 'learning_rate': 1.2080045095828636e-05, 'epoch': 0.46}\n",
      "{'embedding_loss': 0.0126, 'grad_norm': 0.13070808351039886, 'learning_rate': 1.1798196166854568e-05, 'epoch': 0.47}\n",
      "{'embedding_loss': 0.0174, 'grad_norm': 0.33645081520080566, 'learning_rate': 1.1516347237880496e-05, 'epoch': 0.48}\n",
      "{'embedding_loss': 0.0109, 'grad_norm': 0.18354351818561554, 'learning_rate': 1.1234498308906428e-05, 'epoch': 0.49}\n",
      "{'embedding_loss': 0.0113, 'grad_norm': 0.15040890872478485, 'learning_rate': 1.0952649379932356e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8341f077fe174d7bb5b7ee174d962b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/5 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0118, 'grad_norm': 0.24525649845600128, 'learning_rate': 1.0670800450958287e-05, 'epoch': 0.52}\n",
      "{'embedding_loss': 0.0118, 'grad_norm': 0.211159348487854, 'learning_rate': 1.0388951521984216e-05, 'epoch': 0.53}\n",
      "{'embedding_loss': 0.0096, 'grad_norm': 2.0780913829803467, 'learning_rate': 1.0107102593010147e-05, 'epoch': 0.55}\n",
      "{'embedding_loss': 0.0084, 'grad_norm': 0.15078236162662506, 'learning_rate': 9.825253664036077e-06, 'epoch': 0.56}\n",
      "{'embedding_loss': 0.0112, 'grad_norm': 0.13071811199188232, 'learning_rate': 9.543404735062007e-06, 'epoch': 0.57}\n",
      "{'embedding_loss': 0.0147, 'grad_norm': 1.3083480596542358, 'learning_rate': 9.261555806087937e-06, 'epoch': 0.58}\n",
      "{'embedding_loss': 0.0119, 'grad_norm': 0.1224357858300209, 'learning_rate': 8.979706877113867e-06, 'epoch': 0.6}\n",
      "{'embedding_loss': 0.0176, 'grad_norm': 0.12318979948759079, 'learning_rate': 8.697857948139797e-06, 'epoch': 0.61}\n",
      "{'embedding_loss': 0.0075, 'grad_norm': 0.10394389927387238, 'learning_rate': 8.416009019165728e-06, 'epoch': 0.62}\n",
      "{'embedding_loss': 0.0132, 'grad_norm': 0.2787778675556183, 'learning_rate': 8.134160090191658e-06, 'epoch': 0.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a168350cdc7e4b118a892ecfa048817f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/5 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0103, 'grad_norm': 2.3176193237304688, 'learning_rate': 7.852311161217588e-06, 'epoch': 0.65}\n",
      "{'embedding_loss': 0.0087, 'grad_norm': 0.21574115753173828, 'learning_rate': 7.5704622322435186e-06, 'epoch': 0.66}\n",
      "{'embedding_loss': 0.0099, 'grad_norm': 0.07789327949285507, 'learning_rate': 7.2886133032694484e-06, 'epoch': 0.67}\n",
      "{'embedding_loss': 0.0167, 'grad_norm': 1.2971585988998413, 'learning_rate': 7.006764374295378e-06, 'epoch': 0.68}\n",
      "{'embedding_loss': 0.0067, 'grad_norm': 1.9116014242172241, 'learning_rate': 6.724915445321308e-06, 'epoch': 0.7}\n",
      "{'embedding_loss': 0.0104, 'grad_norm': 0.13574464619159698, 'learning_rate': 6.443066516347238e-06, 'epoch': 0.71}\n",
      "{'embedding_loss': 0.0099, 'grad_norm': 0.1575753092765808, 'learning_rate': 6.161217587373168e-06, 'epoch': 0.72}\n",
      "{'embedding_loss': 0.0107, 'grad_norm': 0.7035354375839233, 'learning_rate': 5.879368658399099e-06, 'epoch': 0.74}\n",
      "{'embedding_loss': 0.0138, 'grad_norm': 0.12285279482603073, 'learning_rate': 5.5975197294250285e-06, 'epoch': 0.75}\n",
      "{'embedding_loss': 0.0104, 'grad_norm': 0.5050680041313171, 'learning_rate': 5.315670800450958e-06, 'epoch': 0.76}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d93953ae154aa0aed9ab22b89b1c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/5 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0132, 'grad_norm': 0.14148910343647003, 'learning_rate': 5.033821871476888e-06, 'epoch': 0.77}\n",
      "{'embedding_loss': 0.0134, 'grad_norm': 0.20920413732528687, 'learning_rate': 4.751972942502819e-06, 'epoch': 0.79}\n",
      "{'embedding_loss': 0.0109, 'grad_norm': 0.15351445972919464, 'learning_rate': 4.470124013528749e-06, 'epoch': 0.8}\n",
      "{'embedding_loss': 0.013, 'grad_norm': 0.16835469007492065, 'learning_rate': 4.188275084554679e-06, 'epoch': 0.81}\n",
      "{'embedding_loss': 0.015, 'grad_norm': 1.0735487937927246, 'learning_rate': 3.9064261555806094e-06, 'epoch': 0.82}\n",
      "{'embedding_loss': 0.0071, 'grad_norm': 0.2073952555656433, 'learning_rate': 3.6245772266065393e-06, 'epoch': 0.84}\n",
      "{'embedding_loss': 0.0118, 'grad_norm': 0.1857868880033493, 'learning_rate': 3.342728297632469e-06, 'epoch': 0.85}\n",
      "{'embedding_loss': 0.0107, 'grad_norm': 0.07779091596603394, 'learning_rate': 3.0608793686583995e-06, 'epoch': 0.86}\n",
      "{'embedding_loss': 0.0106, 'grad_norm': 0.11103897541761398, 'learning_rate': 2.7790304396843293e-06, 'epoch': 0.87}\n",
      "{'embedding_loss': 0.01, 'grad_norm': 0.1719900220632553, 'learning_rate': 2.4971815107102596e-06, 'epoch': 0.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbdfadc58e9b484db80ee78db77447c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/5 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0132, 'grad_norm': 1.1034280061721802, 'learning_rate': 2.2153325817361895e-06, 'epoch': 0.9}\n",
      "{'embedding_loss': 0.0086, 'grad_norm': 0.32186993956565857, 'learning_rate': 1.9334836527621198e-06, 'epoch': 0.91}\n",
      "{'embedding_loss': 0.0114, 'grad_norm': 0.0630861446261406, 'learning_rate': 1.6516347237880499e-06, 'epoch': 0.93}\n",
      "{'embedding_loss': 0.0074, 'grad_norm': 0.2523956596851349, 'learning_rate': 1.3697857948139797e-06, 'epoch': 0.94}\n",
      "{'embedding_loss': 0.0067, 'grad_norm': 0.23587703704833984, 'learning_rate': 1.0879368658399098e-06, 'epoch': 0.95}\n",
      "{'embedding_loss': 0.0093, 'grad_norm': 0.42972636222839355, 'learning_rate': 8.0608793686584e-07, 'epoch': 0.96}\n",
      "{'embedding_loss': 0.0086, 'grad_norm': 0.17302197217941284, 'learning_rate': 5.242390078917701e-07, 'epoch': 0.98}\n",
      "{'embedding_loss': 0.0106, 'grad_norm': 0.1944885104894638, 'learning_rate': 2.423900789177001e-07, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb13a873f0c437aa4930f52954595a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/5 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1361.328, 'train_samples_per_second': 46.337, 'train_steps_per_second': 2.896, 'train_loss': 0.02162495925134431, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Modell evaluieren (Nur bei vorhandensein von Testdaten)\n",
    "# metrics = trainer.evaluate()\n",
    "# metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub(\"Chernoffface/fs-setfit-multilable-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setfit import SetFitModel\n",
    "\n",
    "model = SetFitModel.from_pretrained(\"Chernoffface/fs-setfit-multilable-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(\n",
    "    [\n",
    "        \"Die Einzelthemen umfassen: * Hard- and Software-Architecture of Modern Game Systems * Time Management in Milliseconds * Asset Loading and Compression * Physically Based Realtime Rendering and Animations * Handling of Large Game Scenes * Audio Simulation and Mixing * Constraint-Based Physics Simulation * Artificial Intelligence for Games * Multiplayer-Networking * Procedural Content Creation * Integration of Scripting Languages * Optimization and parallelization of CPU and GPU Code Die Übungen enthalten Theorie- und Praxisanteile.\",\n",
    "        \"Aim/ learning outcomes:• learning of the programming language C and understanding of basic concepts of programming• finding and correcting programming errors• development of computer programs and organization of complex projects• working with software libraries• independent analysis of scientific problems and their implementation in CContent:Linux basics, the C++ programming language (e.g. data types, loops, functions, classes, templates), compiler (function, process), OpenSource tools (e.g. make, gnuplot), implementation of numerical algorithms as application examples\",\n",
    "        \"scrum\",\n",
    "        \"Automation Projects, Automation Methods, Development Methods for Automation Systems, Automation with Qualitative Models, Safety and Reliability of Automation Systems\"\n",
    "    ]\n",
    ")\n",
    "[[f for f, p in zip(features, ps) if p] for ps in preds]\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
