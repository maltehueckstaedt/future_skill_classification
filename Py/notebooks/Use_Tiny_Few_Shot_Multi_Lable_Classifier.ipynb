{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anwendung des Classifers\n",
    "\n",
    "## Laden von Paketen\n",
    "\n",
    " Die Anwendung des Classifiers ist so einfach wie m√∂glich gestaltet. In einem ersten Schritt w√§hlen wir unser Enviorment `future-skill-classification` und laden die f√ºr die Vorhersage der Labels n√∂tigen Pakete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadr  # Zum Lesen von R-Daten in Python\n",
    "import os       # Funktionen zum Interagieren mit dem Betriebssystem\n",
    "import pandas as pd  # Datenanalyse und -manipulation mit DataFrames\n",
    "import re # Regrex-Paket f√ºr die Bereinigung von Strings\n",
    "from tqdm import tqdm # Paket f√ºrs Anzeigen von Fortschritt beim Ausf√ºhren von Funktionen\n",
    "from setfit import SetFitModel  # Zum Laden des SetFit-Modells von Hugging Face bzw. aus dem lokalen Ordner heraus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden der HEX-Daten\n",
    "\n",
    "Wir checken das Root-Verzeichnis. Stimmt dieses nicht, bestimmen wir das Korrekte und lesen `db_hex.rds` ein. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checke home-verzeichnis\n",
    "print(os.getcwd())\n",
    "# setze home-verzeichnis\n",
    "os.chdir('c:/Users/Hueck/OneDrive/Dokumente/GitHub/future_skill_classification/')\n",
    "# lade HEX-Daten. Hinweise: Zur√ºckgegben eine Liste mit einem Element (dem Data Frame).\n",
    "# Dieses lassen wir uns mit `.values())[0]` zur√ºckgeben.\n",
    "df_hex = list(pyreadr.read_r('data/db_hex.rds').values())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Classifier zu testen, wenden wir ihn vorerst nur auf 10.000 zuf√§llig gezogene Zeilen an. Daf√ºr *ziehen* wir die entsprechende Stichprobe und speichern sie in dem Objekt `df_hex_sample`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hex_sample = df_hex.sample(n=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einem weiteren Schritt werden die Daten f√ºr die Klassifikation vorbereitet: \n",
    "\n",
    "- `NAs` werden durch leere Strings ersetzt\n",
    "- Die Variablen `titel` und `kursbeschreibung` zusammengef√ºgt und ‚Äì falls eine Kursbeschreibung vorhanden ist ‚Äì ein Doppelpunkt zwischen `titel` und `kursbeschreibung` gesetzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ersetze NaN-Werte in den Spalten 'titel' und 'kursbeschreibung' durch leere Strings\n",
    "df_hex_sample['titel'] = df_hex_sample['titel'].fillna('')\n",
    "df_hex_sample['kursbeschreibung'] = df_hex_sample['kursbeschreibung'].fillna('')\n",
    "\n",
    "# Kombiniere die Spalten und f√ºge den Doppelpunkt nur hinzu, wenn eine Kursbeschreibung vorhanden ist\n",
    "df_hex_sample['sentence'] = df_hex_sample.apply(lambda row: row['titel'] + (\": \" + row['kursbeschreibung'] if row['kursbeschreibung'] else \"\"), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition von Funktionen f√ºr die Vorhersage von Future Skills\n",
    "\n",
    "Um die Future Skills der Kurse der Datenbank mit unserem Modell vorhersagen zu k√∂nnen, erstellen wir eine Funktion, die durch die Zeilen der `db_hex.rds` iteriert und die entsprechenden Sch√§tzungen anhand der oben pr√§parierten `sentence`-Variable vornimmt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fortschrittsbalken f√ºr Pandas aktivieren, um die Fortschritt der Pr√§diktion besser nachvollziehen zu k√∂nnen.\n",
    "tqdm.pandas()\n",
    "\n",
    "# Definiere eine Funktion, die das Modell auf eine Kursbeschreibung anwendet\n",
    "def predict_course_description(description):\n",
    "    # √úberpr√ºfen, ob die Beschreibung ein String ist\n",
    "    if isinstance(description, str):\n",
    "        preds = model(description)\n",
    "        return preds\n",
    "    # Falls `sentence` ein nicht-String-Objekt, gib eine leere Liste\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktion `predict_course_description` gibt uns einen sechsdimensionalen Tensoren zur√ºck, der die Existenz der Future Skills pro Kurs anzeigt:\n",
    "\n",
    "```\n",
    "[1, 0, 0, 1, 0, 0]\n",
    "```\n",
    "F√ºr die Interpretation des Tensors ber√ºcksichtigen wir die Reihenfolge der Variablen unserer Eingangsdaten. Siehe dazu in  `notebooks/Tiny_Few_Shot_Multi_Label_Classifier.ipynb` Sektion `Daten laden`. Im derzeitigen Fall w√§re dies die folgende:\n",
    "\n",
    "```\n",
    "['Data Analytics & KI', 'Softwareentwicklung', 'Nutzerzentriertes Design', 'IT-Architektur', 'Hardware/Robotikentwicklung', 'Quantencomputing']\n",
    "```\n",
    "\n",
    "Dementsprechend w√ºrden in dem obigen Beispiel die Skills 'Data Analytics & KI' sowie 'IT-Architektur' klassifiziert.\n",
    "\n",
    "Um die Tensoren zeilenweise wieder in g√ºltige Labels zu √ºberf√ºhren spezifizieren wir eine weitere Funktion: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_labels = ['Data Analytics & KI', 'Softwareentwicklung', 'Nutzerzentriertes Design', 'IT-Architektur', 'Hardware/Robotikentwicklung', 'Quantencomputing']\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def convert_tensor_to_labels(tensor):\n",
    "    # Falls der Tensor NaN ist, gib None zur√ºck\n",
    "    if pd.isna(tensor).all():  # √úberpr√ºft, ob alle Werte im Tensor NaN sind\n",
    "        return None  # Oder verwende np.nan\n",
    "    \n",
    "    # Sicherstellen, dass die L√§nge des Tensors der L√§nge der fs_labels-Liste entspricht\n",
    "    if len(tensor) != len(fs_labels):\n",
    "        print(f\"Warnung: Unerwartete Tensorgr√∂√üe {len(tensor)}, erwartet: {len(fs_labels)}\")\n",
    "        return 'Fehlerhafte Vorhersage'\n",
    "    \n",
    "    # Identifiziere die Positionen, wo der Wert 1 ist\n",
    "    selected_labels = [fs_labels[i] for i, val in enumerate(tensor) if val == 1]\n",
    "    \n",
    "    # Falls keine Labels ausgew√§hlt wurden, gib None zur√ºck\n",
    "    return ', '.join(selected_labels) if selected_labels else None  # Oder np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell laden, Pr√§diktion durchf√ºhren\n",
    "\n",
    "Das trainierte Modell kann nun entweder lokal oder aus dem Hugging Face-Hub geladen werden. Anschlie√üend wird mit `predict_course_description` die Pr√§diktion pro Kurs durchgef√ºhrt und die resultierenden Tensoren in eine leicht interpretierbare String-Variable √ºberf√ºhrt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden des vortrainierten Modells\n",
    "\n",
    "# Aus dem HF-HUB:\n",
    "#model = SetFitModel.from_pretrained(\"Chernoffface/fs-setfit-multilable-model\")\n",
    "\n",
    "# Lokal:\n",
    "model = SetFitModel.from_pretrained(\"models\")  # √Ñndere den Pfad zu deinem Modell\n",
    "\n",
    "# Prediction anhand von predict_course_description\n",
    "df[\"Pred_Tensor\"] = df[\"sentence\"].progress_apply(predict_course_description)\n",
    "\n",
    "# Umwandlung des Tensors in String-Variable\n",
    "df[\"FS_Skill\"] = df[\"Pred_Tensor\"].progress_apply(lambda x: convert_tensor_to_labels(x))\n",
    "\n",
    "# Tabelle der Resultate:\n",
    "label_counts = df['FS_Skill'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenexport\n",
    "\n",
    "Doneü§ó. Insbesondere bei der Klassifizierung der ganzen HEX Datenbank exportieren wir aufgrund der √ºberaus hohen Menge an Zeilen nach `.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportiere den DataFrame in eine Excel-Datei\n",
    "df.to_csv('daten/hex_classified_fs.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Poetry Future Skills Enviorment",
   "language": "python",
   "name": "poetry_fs_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
